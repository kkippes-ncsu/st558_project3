[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "The Diabetes Health Indicators Data set has 253,680 survey responses to the CDC’s BRFSS2015 (Behavioral Risk Factor Surveillance System 2015). The primary response variable is “Diabetes_binary” which is in two classes: 0 for no diabetes and 1 for prediabetes/diabetes. Additionally, this data set has 21 variables.\nFor the purpose of this EDA and modeling, we will limit the analysis to explore 3 predictor variables in addition to our response variable of “Diabetes_binary”. These include:\n\nHighChol: Adults who have been told they have high cholesterol. A class variable with 0 for no high cholesterol and 1 for high cholesterol.\nBMI: Body Mass Index ranging from 12 to 98 with an average of 28.4.\nAge: A 13-level age category where 1 = 18-24 all the way up to 13 = 80 and older and in between each level is in five year increments. The average age group is 55-59.\n\nThe first two were selected because of prior known relationships to them and diabetes. Age was selected because it would be interesting to know if it truly does have a relationship with the presence of diabetes.\nOverall, the purpose of this EDA is to explore the chosen variables by summarizing them, looking at relationships, and evaluate different models to see their effectiveness in predicting prediabetes/diabetes or no diabetes."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "EDA",
    "section": "",
    "text": "The Diabetes Health Indicators Data set has 253,680 survey responses to the CDC’s BRFSS2015 (Behavioral Risk Factor Surveillance System 2015). The primary response variable is “Diabetes_binary” which is in two classes: 0 for no diabetes and 1 for prediabetes/diabetes. Additionally, this data set has 21 variables.\nFor the purpose of this EDA and modeling, we will limit the analysis to explore 3 predictor variables in addition to our response variable of “Diabetes_binary”. These include:\n\nHighChol: Adults who have been told they have high cholesterol. A class variable with 0 for no high cholesterol and 1 for high cholesterol.\nBMI: Body Mass Index ranging from 12 to 98 with an average of 28.4.\nAge: A 13-level age category where 1 = 18-24 all the way up to 13 = 80 and older and in between each level is in five year increments. The average age group is 55-59.\n\nThe first two were selected because of prior known relationships to them and diabetes. Age was selected because it would be interesting to know if it truly does have a relationship with the presence of diabetes.\nOverall, the purpose of this EDA is to explore the chosen variables by summarizing them, looking at relationships, and evaluate different models to see their effectiveness in predicting prediabetes/diabetes or no diabetes."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "EDA",
    "section": "Data",
    "text": "Data\nFor the following section we are going to read in our data, convert the variables to factors if needed, and do any necessary data checks.\n\n## packages\nlibrary(tidyverse)\n\n## read in the data\ndiabetes_data &lt;- read.csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\n## data type\nstr(diabetes_data)\n\n'data.frame':   253680 obs. of  22 variables:\n $ Diabetes_binary     : num  0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num  1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num  1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num  1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num  40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num  1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num  0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num  0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num  0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num  1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num  1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num  0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num  5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num  18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num  15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num  1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num  0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num  9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num  4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num  3 1 8 6 4 8 7 4 1 3 ...\n\n## check for missing values\nany(is.na(diabetes_data))\n\n[1] FALSE\n\n\nFrom this output we can see that we have a data frame with 253,680 observations of 22 variables. The output of “FALSE” tells us that there are no missing variables. We will now select only our variables of interest and convert them to factors when needed.\n\ndiabetes_eda &lt;- diabetes_data |&gt;\n  mutate(\n    Diabetes = factor(Diabetes_binary, \n                             levels=c(\"0\",\"1\"),\n                             labels=c(\"No\",\"Yes\")),\n    HighChol = factor(HighChol,\n                    levels=c(\"0\",\"1\"),\n                    labels=c(\"No High Cholesterol\",\"High Cholesterol\")),\n    Age = factor(Age,\n               levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\n                            \"9\",\"10\",\"11\",\"12\",\"13\"),\n               labels=c(\"18-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\n                        \"45-49\",\"50-54\",\"55-59\",\"60-64\",\"65-69\",\n                        \"70-74\",\"75-79\",\"80+\"))) |&gt;\n  select(Diabetes, HighChol, BMI, Age)\n\nstr(diabetes_eda)\n\n'data.frame':   253680 obs. of  4 variables:\n $ Diabetes: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ HighChol: Factor w/ 2 levels \"No High Cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ BMI     : num  40 25 28 27 24 25 30 25 30 24 ...\n $ Age     : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n\n\nThis is the data we will use for EDA."
  },
  {
    "objectID": "EDA.html#summarizations",
    "href": "EDA.html#summarizations",
    "title": "EDA",
    "section": "Summarizations",
    "text": "Summarizations\nNow we will explore summary statistics in the form of tables and plots for our chosen variables. We will look at each variable independently (univariate), and then we will look at each relationship between the explanatory variable and the response (bivariate).\n\nDiabetes\nFirst we will look at our response variable, diabetes, by itself. Below we find the proportion of the data has prediabetes/diabetes and the proportion that doesn’t.\n\ndiabetes_eda |&gt;\n  count(Diabetes) |&gt;\n  mutate(prop = n / sum(n))\n\n  Diabetes      n     prop\n1       No 218334 0.860667\n2      Yes  35346 0.139333\n\n\nIt is interesting to see that 86% of the survey responses indicated that they don’t have diabetes/prediabetes. This is a large imbalance and something that will have to be taken into consideration when selecting the most appropriate model.\n\n\nCholesterol\nNext we will look at cholesterol by itself and also it’s relationship with diabetes.\n\n## univariate\ndiabetes_eda |&gt;\n  count(HighChol) |&gt;\n  mutate(prop = n / sum(n))\n\n             HighChol      n      prop\n1 No High Cholesterol 146089 0.5758791\n2    High Cholesterol 107591 0.4241209\n\n## bivariate\ndiabetes_eda |&gt; \n  ggplot(aes(x = HighChol, fill = Diabetes)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Diabetes Proportion by High/Not High Cholesterol\", y = \"Proportion\", fill = \"Diabetes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLooking at cholesterol by itself shows that the survey responses are more evenly split with slightly more of the responses not having high cholesterol. However, when you breakdown cholesterol by diabetes status, we again see that there is a disproportion. Regardless of high cholesterol or not, more subjects do not have diabetes. Although, it is important to note that there is a higher proportion of diabetes when the subject also has high cholesterol.\n\n\nBMI\nThe below summarizes BMI. The first table and graph summarize BMI by itself. We can see that BMI ranges from 12 to 98 and the mean BMI is just above 28. Additionally, the BMI is right-shewed meaning that most data points fall to the left and that the mean is higher than the median.\nThe second table and plot look at the relationship between BMI and Diabetes. They both tell us that subjects with diabetes tend to have a higher BMI but they have the same range of BMIs. Also, grouping BMI by diabetes makes the distributions of BMI more normal than BMI by itself.\n\n## Univariate\n## summary table\nsummary(diabetes_eda$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n## histogram\nggplot(diabetes_eda, aes(x = BMI)) +\n  geom_histogram(binwidth = 1, fill = \"darkgreen\", color = \"white\") +\n  labs(title = \"Distribution of BMI\", x = \"BMI\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n## bivariate\ndiabetes_eda |&gt;\n  group_by(Diabetes) |&gt;\n  summarise(\n    Mean_BMI = mean(BMI, na.rm = TRUE),\n    Median_BMI = median(BMI, na.rm = TRUE),\n    SD_BMI = sd(BMI, na.rm = TRUE),\n    Min_BMI = min(BMI),\n    Max_BMI = max(BMI)\n  )\n\n# A tibble: 2 × 6\n  Diabetes Mean_BMI Median_BMI SD_BMI Min_BMI Max_BMI\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 No           27.8         27   6.29      12      98\n2 Yes          31.9         31   7.36      13      98\n\nggplot(diabetes_eda, aes(x = BMI, fill = Diabetes)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"BMI Density by Diabetes Status\", x = \"BMI\", y = \"Density\") +\n  scale_fill_manual(values = c(\"No\" = \"navy\", \"Yes\" = \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nAge\nAs a reminder, age is a 13-level age category where 1 = 18-24 all the way up to 13 = 80 and older and in between each level is in five year increments.Summary statistics shows that there are more reponses in the higher age groups (50 and older) and the lowest number of responses came from the 18-24 age group.\n\n## univariate\ndiabetes_eda |&gt;\n  count(Age) |&gt;\n  mutate(prop = n / sum(n))\n\n     Age     n       prop\n1  18-24  5700 0.02246925\n2  25-29  7598 0.02995112\n3  30-34 11123 0.04384658\n4  35-39 13823 0.05448991\n5  40-44 16157 0.06369048\n6  45-49 19819 0.07812599\n7  50-54 26314 0.10372911\n8  55-59 30832 0.12153895\n9  60-64 33244 0.13104699\n10 65-69 32194 0.12690792\n11 70-74 23533 0.09276648\n12 75-79 15980 0.06299275\n13   80+ 17363 0.06844450\n\n## bivariate\ndiabetes_eda |&gt; \n  ggplot(aes(x = Age, fill = Diabetes)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Diabetes Proportion by Age Group\", y = \"Proportion\", fill = \"Diabetes\") +\n  scale_fill_manual(values = c(\"No\" = \"coral\", \"Yes\" = \"turquoise\"))+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe bar plot shows the proportion of subjects with and without diabetes for all of the age groups. We observe that younger age groups have very low proportions of diabetes. As age increases, the proportion of those with diabetes also increases. 70-74 has the highest proportion of individuals with diabetes."
  },
  {
    "objectID": "EDA.html#conclusion",
    "href": "EDA.html#conclusion",
    "title": "EDA",
    "section": "Conclusion",
    "text": "Conclusion\nAfter looking at these three variables, we do see some relationships between diabetes and our three explanatory variables. We will next explore some predict models in the next modeling steps.\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "The Diabetes Health Indicators Data set has 253,680 survey responses to the CDC’s BRFSS2015 (Behavioral Risk Factor Surveillance System 2015). The primary response variable is “Diabetes_binary” which is in two classes: 0 for no diabetes and 1 for prediabetes/diabetes. This data is unbalanced with the largest class being the no diabetes class. Additionally, this data set has 21 variables.\nIn this analysis, we will be using log loss as our metric to evaluate the best model and will use 5 fold cross-validation to select the best model for all model types. The goal is to pick the best model that gives the best prediction whether or not someone has diabetes.\nFirst we will split the data into training and test sets to use for modeling. By doing this, it will help with over fitting as our goal is for the model to predict well on unseen data. We will use logistic regression, classification trees, and random forest models."
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "The Diabetes Health Indicators Data set has 253,680 survey responses to the CDC’s BRFSS2015 (Behavioral Risk Factor Surveillance System 2015). The primary response variable is “Diabetes_binary” which is in two classes: 0 for no diabetes and 1 for prediabetes/diabetes. This data is unbalanced with the largest class being the no diabetes class. Additionally, this data set has 21 variables.\nIn this analysis, we will be using log loss as our metric to evaluate the best model and will use 5 fold cross-validation to select the best model for all model types. The goal is to pick the best model that gives the best prediction whether or not someone has diabetes.\nFirst we will split the data into training and test sets to use for modeling. By doing this, it will help with over fitting as our goal is for the model to predict well on unseen data. We will use logistic regression, classification trees, and random forest models."
  },
  {
    "objectID": "Modeling.html#data",
    "href": "Modeling.html#data",
    "title": "Modeling",
    "section": "Data",
    "text": "Data\n\n## load the necessary packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(caret)\n\n## read in the data\ndiabetes_data &lt;- read.csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\n## factor all necessary variables used for modeling and select ones wanted\ndiabetes_modeling &lt;- diabetes_data |&gt;\n  mutate(Diabetes = factor(Diabetes_binary,\n                           levels=c(\"0\",\"1\"),\n                           labels=c(\"No_Diabetes\",\"Prediabetes_or_Diabetes\")),\n         HighBP = factor(HighBP,\n                         levels=c(\"0\",\"1\"),\n                         labels=c(\"No_High BP\",\"High_BP\")),\n         HighChol = factor(HighChol,\n                           levels=c(\"0\",\"1\"),\n                           labels=c(\"No_High_Cholesterol\",\"High_Cholesterol\")),\n         Smoker = factor(Smoker,\n                         levels=c(\"1\",\"0\"),\n                         labels=c(\"Smoker\",\"Not_Smoker\")),\n         Stroke = factor(Stroke,\n                         levels=c(\"1\",\"0\"),\n                         labels=c(\"Had_Stroke\",\"No_Stroke\")),\n         Heart_Disease_or_Attack = factor(HeartDiseaseorAttack,\n                                          levels=c(\"1\",\"0\"),\n                                          labels=c(\"Heart_Disease\",\"No_Heart_Disease\")),\n         Heavy_Alcohol_Consumption = factor(HvyAlcoholConsump,\n                                            levels=c(\"1\",\"0\"),\n                                            labels=c(\"Heavy_Alcohol\",\n                                                     \"No_Heavy_Alcohol\")),\n         General_Health = factor(GenHlth,\n                                 levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                                 labels=c(\"Excellent\",\"Very_Good\",\"Good\",\"Fair\",\"Poor\")),\n         Sex = factor(Sex,\n                      levels=c(\"0\",\"1\"),\n                      labels=c(\"Female\",\"Male\")),\n         Age = factor(Age,\n                      levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\n                               \"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                      labels=c(\"18-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\n                               \"45-49\",\"50-54\",\"55-59\",\"60-64\",\"65-69\",\n                               \"70-74\",\"75-79\",\"80+\")),\n         Income = factor(Income,\n                         levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                         labels=c(\"&lt;$10,000\",\n                                  \"$10,000-$15,000\",\n                                  \"$15,000-$20,000\",\n                                  \"$20,000-$25,000\",\n                                  \"$25,000-$35,000\",\n                                  \"$35,000-$50,000\",\n                                  \"$50,000-$75,000\",\n                                  \"$75,000+\")),\n         ) |&gt;\n  select(Diabetes, HighBP, HighChol, BMI, Smoker, Stroke, Heart_Disease_or_Attack,\n         Heavy_Alcohol_Consumption, General_Health, Sex, Age, Income)\n\nNow that we have selected the data for the models, we are going to split it into the train and test sets.\n\n## set seed\nset.seed(101)\n\n## split the data into train and test sets\ndiabetes_split &lt;- initial_split(diabetes_modeling, prop = 0.7)\ntrain &lt;- training(diabetes_split)\ntest &lt;- testing(diabetes_split)\n\nWe also need to establish our 5 fold cross-validation.\n\ntr_ctrl &lt;- trainControl(\n  method = \"cv\",\n  number = 5,\n  classProbs = TRUE,\n  summaryFunction = mnLogLoss\n)\n\nNow let’s create our models.\n\nLogistic Regression\nLogistic regression is a generalized linear modeling technique used to predict the probability of a binary outcome and it cane be used for when the outcome is categorical. It uses a logit function to model the relationship between predictors and the log-odds of an event occurring. We are using it for this data because our response variable, diabetes, is a binary classification which is what these types of models are designed for. Below we will look at 3 different LR models and choose our best one.\n\n## LR model 1\nLR1 &lt;- train(\n  Diabetes ~ .,\n  data = train,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = tr_ctrl,\n  metric = \"logLoss\"\n)\n\n## LR model 2\nLR2 &lt;- train(\n  Diabetes ~ HighChol + HighBP + Smoker + Stroke,\n  data = train,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = tr_ctrl,\n  metric = \"logLoss\"\n)\n\n## LR model 2\nLR3 &lt;- train(\n  Diabetes ~ General_Health + Sex + Age + Income,\n  data = train,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = tr_ctrl,\n  metric = \"logLoss\"\n)\n\n## compare the 3 models\nLogLoss_Results &lt;- rbind(\n  data.frame(Model = \"Model 1\", LR1$results),\n  data.frame(Model = \"Model 2\", LR2$results),\n  data.frame(Model = \"Model 3\", LR3$results)\n)\n\nLogLoss_Results\n\n    Model parameter   logLoss   logLossSD\n1 Model 1      none 0.3196442 0.002190742\n2 Model 2      none 0.3589805 0.001679228\n3 Model 3      none 0.3440985 0.001870641\n\n\nBased off of our results, we can conclude that the model with the lowest log loss is our best model so in this case it will be Model 1 which used all of the preselected predictors.\n\n\nClassification Trees\nTree based methods attempt to split up predictor space into regions. Within each region, a different prediction can be made. Classification trees are used if the goal is to classify (predict) group membership. Usually the most prevalent class in the region is used as the prediction. In this case, predicting diabetes from the various explanatory variables may involve complex interactions so using a classification tree will help capture those. Decision trees help filter for the important model features and are easy to interpret.\n\n## create recipe\ntree_rec &lt;- recipe(Diabetes ~ ., data = train) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes())\n\n## define the tuning grid\ntree_grid &lt;- expand.grid(cp = seq(0.001, 0.05, by = 0.005))\n\n## fit the model\ntree_model &lt;- train(\n  tree_rec,\n  data = train,\n  method = \"rpart\",\n  trControl = tr_ctrl,\n  tuneGrid = tree_grid,\n  metric = \"logLoss\"\n)\n\n\nAttaching package: 'rpart'\n\n\nThe following object is masked from 'package:dials':\n\n    prune\n\n# Check best\ntree_model$results |&gt; arrange(logLoss)\n\n      cp   logLoss    logLossSD\n1  0.001 0.3574633 1.313806e-03\n2  0.006 0.4032255 1.976641e-05\n3  0.011 0.4032255 1.976641e-05\n4  0.016 0.4032255 1.976641e-05\n5  0.021 0.4032255 1.976641e-05\n6  0.026 0.4032255 1.976641e-05\n7  0.031 0.4032255 1.976641e-05\n8  0.036 0.4032255 1.976641e-05\n9  0.041 0.4032255 1.976641e-05\n10 0.046 0.4032255 1.976641e-05\n\n\nOur best model had a complexity parameter of 0.001 with a log loss of 0.3576."
  }
]